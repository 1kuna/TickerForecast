{"trial_id": "027", "hyperparameters": {"space": [{"class_name": "Boolean", "config": {"name": "timeseries_block_1/rnn_block_1/bidirectional", "default": true, "conditions": []}}, {"class_name": "Choice", "config": {"name": "timeseries_block_1/rnn_block_1/layer_type", "default": "lstm", "conditions": [], "values": ["gru", "lstm"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "timeseries_block_1/rnn_block_1/num_layers", "default": 2, "conditions": [], "values": [1, 2, 3], "ordered": true}}, {"class_name": "Choice", "config": {"name": "regression_head_1/dropout", "default": 0, "conditions": [], "values": [0.0, 0.25, 0.5], "ordered": true}}, {"class_name": "Choice", "config": {"name": "optimizer", "default": "adam", "conditions": [], "values": ["adam", "sgd", "adam_weight_decay"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "learning_rate", "default": 0.001, "conditions": [], "values": [0.1, 0.01, 0.001, 0.0001, 2e-05, 1e-05], "ordered": true}}], "values": {"timeseries_block_1/rnn_block_1/bidirectional": true, "timeseries_block_1/rnn_block_1/layer_type": "lstm", "timeseries_block_1/rnn_block_1/num_layers": 2, "regression_head_1/dropout": 0.25, "optimizer": "adam_weight_decay", "learning_rate": 0.0001}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\engine\\tuner.py\", line 101, in _build_and_fit_model\n    _, history = utils.fit_with_adaptive_batch_size(\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 88, in fit_with_adaptive_batch_size\n    history = run_with_adaptive_batch_size(\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 101, in run_with_adaptive_batch_size\n    history = func(x=x, validation_data=validation_data, **fit_kwargs)\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 89, in <lambda>\n    batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.InternalError: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_12' defined at (most recent call last):\n    File \"k:\\Git\\KUNA\\TickerForecast\\SoloAlpha2.py\", line 81, in <module>\n      clf.fit(x_train, y_train, epochs=20, shuffle=False, batch_size=256, callbacks=callbacks)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\tasks\\time_series_forecaster.py\", line 268, in fit\n      super().fit(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\tasks\\time_series_forecaster.py\", line 88, in fit\n      history = super().fit(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\tasks\\structured_data.py\", line 139, in fit\n      history = super().fit(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\auto_model.py\", line 292, in fit\n      history = self.tuner.search(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\engine\\tuner.py\", line 193, in search\n      super().search(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 230, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\engine\\tuner.py\", line 101, in _build_and_fit_model\n      _, history = utils.fit_with_adaptive_batch_size(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 88, in fit_with_adaptive_batch_size\n      history = run_with_adaptive_batch_size(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 101, in run_with_adaptive_batch_size\n      history = func(x=x, validation_data=validation_data, **fit_kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\autokeras\\utils\\utils.py\", line 89, in <lambda>\n      batch_size, lambda **kwargs: model.fit(**kwargs), **fit_kwargs\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 997, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 481, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 940, in apply_gradients\n      super().apply_gradients(grads_and_vars)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in apply_gradients\n      self._internal_apply_gradients(grads_and_vars)\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 943, in _internal_apply_gradients\n      tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 993, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"C:\\Users\\zcane\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 988, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_12'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_12}}]] [Op:__inference_train_function_67869]\n"}